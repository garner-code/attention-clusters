RPE = compute_RPE(current_outcome, Qas[Qas_type, i] + sum(Vs[Vs_type, i])) # compute the RPE to be distributed between
# the action and the context - i.e. the value of the state
# update Qas
Qas[Qas_type, i+1] <- Qas[Qas_type, i] + alpha*(1-gamma[i])*RPE # gamma will change, therefore, can't be exchangeable with alpha (I assume)
Qas[!rownames(Qas) %in% Qas_type, i+1] <- Qas[rownames(Qas) != Qas_type, i]
##### Testing Qas learning
# t|l should get to 0.5, t|h should go higher to 0.8 odd, the d|h and d|l should both go to 0.1
# convergence should be slower because less of the RPE is going into this signal
# this should learn that tgt|h > tgt|d, so I need to invoke a WAV update rule that takes whichever is greater Q(a), or Q(a|s)
if(trialtype == "HN") WAVs["t", i+1] <- max(Qs["t", i+1], Qas["t|h", i+1])
if(trialtype == "LN") WAVs["t", i+1] <- max(Qs["t", i+1], Qas["t|l", i+1])
# WAVs["hd", i+1] <- Qas["d|h", i+1]
# WAVs["ld", i+1] <- Qas["d|l", i+1]
#### Qas learning works for the WAV rules. At this point, we would be predicting the opposite of VMAC
#### But also, need to write a function to plot Qas, Qas works! final value of the tgt depends on the V of the distractors
# now update Vs - the Vs RPE has to get distributed between the target and distractor
# here I will use a rescorla wagner update rule - the idea is to distribute according to
# how well is the outcome predicted by the target and by the distractor.
# but I want to code another iteration where its based on physical proximity (and then maybe both?)
Vs <- update_Vs_rw(Vs, Vs_type, gamma[i]*RPE, alpha, b, i)
# Vs is working how I think
# NEXT to work out the WAVs:
#   # next I need to update the WAVs for the next trial as well as the gamma that proportions
#   # the reward between the Q(a,s) and the V(s), and then we can move to the next
#   # trial
#   # possible rules for distributing between Q(as) and V(s):
#    strategy_RPE <- Qas[Qas_type, i+1] - Qs[Qa, i+1] # this gives how much better the estimated Q action|state is than Qa
#   # this is positive when tracking the action|state is better than when just tracking the action, and negative when you can ditch the context of the state for the action, thus a positib value should work towards increasing
#   # gamma so that more weight gets put onto the value of the state, which can then be distributed between the target and
#   # the distractor (and vice versa, for times you can ignore the state) - this will certainly benefit the high value distractor
#   # over the low value distractor. For the high value state, this should converge to 0.33 for high vs a, and -0.33 for low vs a
#   # gamma would need to be bound to 0, so the negative can only move it towards zero
#     gamma[i+1] <- gamma[i] + alpha*strategy_RPE # so when the
#   # A QUESTION FOR FUTURE: is the volatility in early estimates enough to give the HV stimulus its gain, or do we need the
#   # extra mechanism below?
#
#   # For volatility: we have the following differences:
#   # 1. The size of the RPE | just Qs - Qs should get to ~0.5. If the average of both contexts is 50 (HV experiements),
#   # then the average value estimate will be the same as the HV condition. However, the average RPE will be smaller
#   # across both contexts, than when you are in the high variability condition.
#   # This needs to be included in the gamma estimate, cos, RPE will be up to .5
#
#   # There are 2 ways to know the state is special:
#   # First, your estimate of your action given the state is larger than your estimate of an action overall
#   # Second, if the change in the data - i.e. the outcomes, from trial to trial is large, this could be a signal
#   # that there is more to learn about the state, perhaps if you change your policy in this state, then
#   # you could reduce the variability in your estimate. Therefore, if the RPE is larger in this state compared to overall,
#   # then you should put more weight on assigning value to other items in the state.
#   # so for each trial, I will compare the size of the learned RPE size for the Qs overall relative to the one in each state
#
#   # I need to add a volatility measure  that we also use here, as volatility
#   # of outcomes would suggest that more weight should be given to finding out about the state
#
#
#   # Now update the WAVs for the learned things
#     # update rule = max(Qs, )
# #    WAVs_idx <-
}
plot_X(Qs, "Qs")
legend(1500, 0.3, legend=rownames(Qs), lty=1, col=wesanderson::wes_palette("AsteroidCity2")[1:nrow(Qs)])
plot_X(Qas, "Qas")
legend(1500, 0.6, legend=rownames(Qas), lty=1, col=wesanderson::wes_palette("AsteroidCity2")[1:nrow(Qas)])
plot_X(Vs, "V")
legend(1500, 0.015, legend=rownames(Vs), lty=1, col=wesanderson::wes_palette("AsteroidCity2")[1:nrow(Vs)])
Ks = 2
t = 2
ts = 100
alpha = 2
for (i in 1:ts){}
for (i in 1:ts){
ts = 100 # number of trials
c = rep(0, ts)
c[1] = 1
x = seq(-pi, pi, .01)
y = dnorm(x, mean = 0, sd = 10)
plot(x,y, type="l")
x = seq(-100, 100, .01)
y = dnorm(x, mean = 0, sd = 10)
plot(x,y, type="l")
quantile(y, .05, .01, .00001)
qnorm(.95, mean = 0, sd = 10)
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue")
abline(v=qnorm(.99, mean = 0, sd = 10), col="purple")
abline(v=qnorm(.999999999999, mean = 0, sd = 10), col="red")
alty = dnorm(x, mean = 5, sd = 10)
points(x,alty,type="l",col="green")
plot(x,y, type="l")
alty = dnorm(x, mean = 15, sd = 10)
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue")
abline(v=qnorm(.99, mean = 0, sd = 10), col="purple")
alty = dnorm(x, mean = 20, sd = 10)
plot(x,y, type="l")
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue")
abline(v=qnorm(.99, mean = 0, sd = 10), col="purple")
abline(v=qnorm(.999999999999, mean = 0, sd = 10), col="red")
alty = dnorm(x, mean = 25, sd = 10)
plot(x,y, type="l")
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue")
alty = dnorm(x, mean = 30, sd = 10)
plot(x,y, type="l")
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue")
abline(v=qnorm(.99, mean = 0, sd = 10), col="purple")
abline(v=qnorm(.999999999999, mean = 0, sd = 10), col="red")
gamma = 30/10
delta = 30/10
# alpha with alternate
x = seq(-100, 100, .01)
y = dnorm(x, mean = 0, sd = 10)
alty = dnorm(x, mean = 30, sd = 10)
delta = 30/10
plot(x,y, type="l", col="grey")
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue", lty=2)
abline(v=qnorm(.95, mean = 0, sd = 10), col="orange", lty=2)
abline(v=qnorm(.999999999999, mean = 0, sd = 10), col="red", lty=2)
# alpha with alternate
x = seq(-100, 100, .01)
y = dnorm(x, mean = 0, sd = 10)
alty = dnorm(x, mean = 30, sd = 10)
delta = 30/10
plot(x,y, type="l", col="grey")
points(x,alty,type="l",col="darkgreen")
abline(v=qnorm(.95, mean = 0, sd = 10), col="blue", lty=2)
abline(v=qnorm(.99, mean = 0, sd = 10), col="orange", lty=2)
abline(v=qnorm(.999999999999, mean = 0, sd = 10), col="red", lty=2)
# initialise empty arrays
alphas <- rep(0,length(data))
betas <- alphas
s <- alphas
f <- alphas
data = sample(c(1,0), size=100, replace=TRUE, prob=c(.8,.2))
data
# initialise empty arrays
alphas <- rep(0,length(data))
betas <- alphas
s <- alphas
f <- alphas
data
i = 1
s[i] <- data[i]
f[i] <- 1-data[i]
decay = .9
s
f
i = 2
decay*s[i-1]
s[i] <- decay*s[i-1] + data[i]
f[i] <- decay*f[i-1] + 1-data[i]
s
data[i]
f
alphas[i] <- alpha+s[i]
alpha=1,beta=1
alpha+s[i]
alpha = 1
beta = 1
alpha+s[i]
beta+f[i]
alphas[i] <- alpha+s[i]
betas[i] <- beta+f[i]
beta_map <- (alphas-1) / (alphas+betas-2)
beta_map
beta_variance <- alphas*betas / ((alphas+betas)^2 * (alphas+betas+1))
# K. Garner, 2025
# this function plots a beta distribution for a given alpha
# and beta
x = seq(0, 1, by=.01)
? dbeta
alpha = 0.474
beta = 0.5
plot(x,
dbeta(x, alpha, beta),
type="l",
lwd=1.5,
col="#7bccc4")
plot_beta_distribution_for_given_trial <- function(alpha, beta){
# K. Garner, 2025
# this function plots a beta distribution for a given alpha
# and beta
x = seq(0, 1, by=.01)
p <- plot(x,
dbeta(x, alpha, beta),
type="l",
lwd=1.5,
col="#7bccc4",
xlab = "p",
ylab = "density")
}
x = seq(0, 1, by=.01)
p <- plot(x,
dbeta(x, alpha, beta),
type="l",
lwd=1.5,
col="#7bccc4",
xlab = "p",
ylab = "density")
p
setwd("~/Documents/projects/attention-clusters/explore")
# set wd to source file location
rm(list=ls())
set.seed(42) # meaning of life
library(tidyverse)
library(pracma)
library(car)
library(gridExtra)
library(plotly)
library(htmlwidgets)
library(diptest)
library(mclust)
library(quantreg)
source("../R/behavioural-data-analysis-functions.R")
#############################################################################
## source previous work
source("simul_cue_use.R")
head(both)
head(val)
#### K. Garner
#### goal is to find out if participants use both value and spatial cues
#### on the same trials
#### to get here, I cloned my attention-clusters repo locally, and downloaded
#### the 'clusters' data folder from google drive, however, the latter
#### should also be on cloud.rdm.uq.edu.au
#### clusters is in the 'project' folder
##############################################################################
#### clear stuff and load packages
# set wd to source file location
rm(list=ls())
set.seed(42) # meaning of life
library(tidyverse)
library(pracma)
library(car)
library(gridExtra)
library(plotly)
library(htmlwidgets)
source("../R/behavioural-data-analysis-functions.R")
##############################################################################
#### functions
get_me_and_cert_ps <- function(m, bf_p = .05){
# which subs show a sig effect of both?
if (m["cert", 4] < bf_p & m["reward_type", 4] < bf_p){
y = TRUE
} else {
y = FALSE
}
if (y) m
}
get_single <- function(m, bf_p = .05, fx_keep = "cert", fx_reject = "reward_type"){
# which subs show a sig effect of both?
if (m[fx_keep, 4] < bf_p & m[fx_reject, 4] > bf_p){
y = TRUE
} else {
y = FALSE
}
if (y) m
}
do_sub_plts <- function(dat, sub_n, fnm = 'both_sub-%d.pdf'){
ydat <- dat %>% filter(sub == sub_n) %>% filter(cert == ".2" | cert == ".8") %>%
summarise(miny = min(rt),
maxy = max(rt))
# pa <- dat %>% filter(sub == sub_n) %>% filter(cert == ".2") %>%
#   ggplot(aes(x = reward_type, y = rt, group = p5_split, colour = p5_split)) +
#   geom_point(position = position_jitter(w = .05, h = .01)) +
#   theme(legend.position = "none") + ggtitle("cert = .2") +
#   ylim(ydat$miny, ydat$maxy)
pa <- dat %>% filter(sub == sub_n) %>% filter(cert == ".8") %>%
ggplot(aes(x = reward_type, y = rt, group = p5_split, colour = p5_split)) +
geom_point(position = position_jitter(w = .05, h = .01)) +
ggtitle("cert = .8") +
theme(legend.position = "none") +
ylim(ydat$miny, ydat$maxy)
pb <- dat %>% filter(sub == sub_n) %>% filter(cert == ".8") %>%
ggplot(aes(x=rt, group=reward_type, colour=reward_type)) +
stat_ecdf(pad = FALSE)
p <- arrangeGrob(pa, pb, ncol = 2)
ggsave(paste("../images", sprintf(fnm, sub_n), sep = "/"), p, units = "cm", width = 16, height = 16)
}
do_sub_plts_valsplt <- function(dat, sub_n, fnm = 'both_val_sub-%d.pdf'){
ydat <- dat %>% filter(sub == sub_n) %>%
filter(reward_type == "htgt/ldst" | reward_type == "ltgt/hdst") %>%
summarise(miny = min(rt),
maxy = max(rt))
pa <- dat %>% filter(sub == sub_n) %>% filter(reward_type == "htgt/ldst") %>%
ggplot(aes(x = cert, y = rt, group = p5_split, colour = p5_split)) +
geom_point(position = position_jitter(w = .05, h = .01)) +
theme(legend.position = "none") + ggtitle("hvl") +
ylim(ydat$miny, ydat$maxy)
pb <- dat %>% filter(sub == sub_n) %>% filter(reward_type == "ltgt/hdst") %>%
ggplot(aes(x = cert, y = rt, group = p5_split, colour = p5_split)) +
geom_point(position = position_jitter(w = .05, h = .01)) +
ggtitle("lvh") +
theme(legend.position = "none") +
ylim(ydat$miny, ydat$maxy)
p <- arrangeGrob(pa, pb, ncol = 2)
ggsave(paste("../images", sprintf(fnm, sub_n), sep = "/"), p, units = "cm", width = 16, height = 16)
}
##############################################################################
#### load data
load("../clusters/derivatives/cleaned_data.Rmd")
View(clean_dat)
# clean_dat has only correct trials, does have condition sorting
# and has had RT outliers removed
##############################################################################
#### Q1. Is it sensible to do a detrend to remove the effect of trial?
random_subs <- with(clean_dat, sample(unique(sub), size = 20))
clean_dat %>% filter(sub %in% random_subs) %>%
ggplot(aes(x = t, y=rt)) +
geom_line() + facet_wrap(~sub, scales="free_y")
clean_dat %>% filter(sub %in% random_subs) %>%
ggplot(aes(x = t, y=detrend(rt, tt = "linear"))) +
geom_line() + facet_wrap(~sub, scales="free_y")
# mixed, for some subs it does look like it might help
# have decided it is not worth it, having looked at the output
##############################################################################
#### Q2. for each sub, who shows
mods <- lapply(unique(clean_dat$sub), sub.model, data = clean_dat)
names(mods) <- unique(clean_dat$sub)
fx <- row.names(mods[[1]])
bf_p <- .05/7
# a main effect of both certainty and value?
both <- lapply(mods, get_me_and_cert_ps)
both <- both[!sapply(both, is.null)]
both_subs <- names(both)
# a main effect of only certainty
cert <- lapply(mods, get_single)
cert <- cert[!sapply(cert, is.null)]
cert_subs <- names(cert)
# only a main effect of value
val <- lapply(mods, get_single, fx_keep = "reward_type", fx_reject = "cert")
val <- val[!sapply(val, is.null)]
val_subs <- names(val)
##### 129 subjects
#############################################################################
# Q3. do data patterns suggest single or multiple cue use per trial?
## CERT
# first, for each sub, define two columns, ranking if rts are in the
# top or bottom 50% for cert = .8 condition, same for .2 condition
# do the same for < .25, > .75
qrtls <- clean_dat %>% group_by(sub, cert) %>%
summarise(p33 = quantile(rt, .33),
p5 = quantile(rt, .5),
p66 = quantile(rt, .66))
dat <- inner_join(clean_dat, qrtls, by = c("sub", "cert"))
dat <- dat %>% mutate(p5_split = if_else(rt < p5, "lower", "upper"),
q33_split = if_else(rt < p33, "lower", if_else(rt > p66, "upper", "mid")))
# for each sub, plot .2 and .8 RTs on separate plots, by value condition
# first try points, coloured by upper vs lower
lapply(as.numeric(both_subs), do_sub_plts, dat = dat)
lapply(as.numeric(cert_subs), do_sub_plts, dat = dat, fnm = 'cert_sub-%d.pdf')
lapply(as.numeric(val_subs), do_sub_plts, dat = dat, fnm = 'val_sub-%d.pdf')
## VALUE
# first, for each sub, define two columns, ranking if rts are in the
# top or bottom 50% for cert = .8 condition, same for .2 condition
# do the same for < .25, > .75
qrtls <- clean_dat %>% group_by(sub, reward_type) %>%
summarise(p33 = quantile(rt, .33),
p5 = quantile(rt, .5),
p66 = quantile(rt, .66))
dat <- inner_join(clean_dat, qrtls, by = c("sub", "reward_type"))
dat <- dat %>% mutate(p5_split = if_else(rt < p5, "lower", "upper"),
q33_split = if_else(rt < p33, "lower", if_else(rt > p66, "upper", "mid")))
lapply(as.numeric(both_subs), do_sub_plts_valsplt, dat = dat)
both_subs <- as.numeric(names(both)) # get the subs that showed an effect
get_qq_coefs <- function(data, sub_n, taus = seq(0.1, 0.9, by=0.1),
cert_val = ".8"){
tmp = clean_dat %>% filter(sub == sub_n & cert == cert_val)
out = do.call(rbind, lapply(taus,
function(x) coef(rq(rt ~ reward_type, tau=x,
data=tmp))))
out <- as_tibble(out)
names(out) <- c("int", "htgtldst", "ltgtldst", "ltgthdst")
out$sub = sub_n
out$q = taus
out
}
both_subs_coefs <- do.call(rbind, lapply(both_subs, get_qq_coefs, data=clean_dat))
both_subs_coefs <- both_subs_coefs %>% pivot_longer(cols=c(htgtldst, ltgtldst, ltgthdst),
names_to="reward_cond",
values_to ="beta")
both_subs_coefs$new_ref <- NA
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "ltgtldst"] = 1
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "htgtldst"] = 2
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "ltgthdst"] = 3
both_subs_coefs$new_ref <- as.factor(both_subs_coefs$new_ref)
levels(both_subs_coefs$new_ref) <- c("ltgtldst", "htgtldst", "ltgthdst")
res = summary(lm(beta ~ q*new_ref, data=both_subs_coefs))
res
both_subs_coefs %>% ggplot(aes(x=q, y=beta, group_by=as.factor(sub),
col=new_ref)) +
geom_line() + facet_wrap(~new_ref)
ggsave("../images/qreg/betas_by_q_inds.pdf", units = "cm", width = 16, height = 16)
# replot as a grouped boxplot
both_subs_coefs %>% ggplot(aes(x=as.factor(q), y=beta, colour=new_ref,
group_by=reward_cond)) +
geom_boxplot(notch=TRUE)
ggsave("../images/qreg/betas_by_bp.pdf", units = "cm", width = 16, height = 16)
both_subs_coefs %>% ggplot(aes(x=beta, group_by=new_ref, colour=new_ref, fill=new_ref)) +
geom_histogram(alpha=0.5) + facet_wrap(~as.factor(q))
ggsave("../images/qreg/betas_hists.pdf", units = "cm", width = 16, height = 16)
# simulate idea
set.seed(42)
library(tidyverse)
n_trials <- 160
beta_cert <- .9
beta_val <- c(0, 0, 0, .2)
error <- rnorm(n_trials, mean = 0, sd = .1)
design <- matrix(c(1, 0, 0, 0, 0, 1, 0, 0,
0, 0, 1, 0, 0, 0, 0, 1), nrow = 4, ncol = 4)
design <- kronecker(design, rep(1, times=40))
y <- beta_cert + design %*% beta_val + error
### now make dataframe
dat <- data.frame(sub = 1,
reward_type = rep(c("lvl", "hvh", "hvl", "lvh"), each = 40),
rt = y)
prt <- dat %>% group_by(sub) %>% summarise(p5 = quantile(rt, .5))
dat$p5 <- prt$p5
dat <- dat %>% mutate(p5_split = if_else(rt < p5, 1, 2))
## now plot the data
# as before
dat %>% ggplot(aes(x = reward_type, y = rt, group = p5_split, colour = p5_split)) +
geom_point(position = position_jitter(w = .05, h = .01)) +
ggtitle("cert = .8") +
theme(legend.position = "none")
# as ecdf
dat %>% ggplot(aes(x = rt, group = reward_type, colour = reward_type)) +
stat_ecdf(pad = FALSE)
##### step 2, bimodal distribution
# here I assume that only in the last group is there a probability
# of selecting from 1 of 2 distributions, either the distribution
# that forms the remaining three conditions or, the value
# based distraction
nu_beta_val <- 1.25 # value effect must be > valid effect to work
lvh_cond <- sample(c(beta_cert, nu_beta_val), size = 40, prob = c(.8, .2),
replace = TRUE)
y <- c(rep(beta_cert, each = 120), lvh_cond) + error
dat <- data.frame(sub = 1,
reward_type = rep(c("lvl", "hvh", "hvl", "lvh"), each = 40),
rt = y)
prt <- dat %>% group_by(sub) %>% summarise(p5 = quantile(rt, .5))
dat$p5 <- prt$p5
dat <- dat %>% mutate(p5_split = if_else(rt < p5, 1, 2))
## now plot the data
# as before
dat %>% ggplot(aes(x = reward_type, y = rt, group = p5_split, colour = p5_split)) +
geom_point(position = position_jitter(w = .05, h = .01)) +
ggtitle("cert = .8") +
theme(legend.position = "none")
# as ecdf
dat %>% ggplot(aes(x = rt, group = reward_type, colour = reward_type)) +
stat_ecdf(pad = FALSE)
#### K. Garner
#### following up hypotheses re: quantiles aka using quantile regression
##############################################################################
#### clear stuff and load packages
# set wd to source file location
rm(list=ls())
set.seed(42) # meaning of life
library(tidyverse)
library(pracma)
library(car)
library(gridExtra)
library(plotly)
library(htmlwidgets)
library(diptest)
library(mclust)
library(quantreg)
source("../R/behavioural-data-analysis-functions.R")
#############################################################################
## source previous work
source("simul_cue_use.R")
head(both)
tail(both)
both_subs <- as.numeric(names(both)) # get the subs that showed an effect
get_qq_coefs <- function(data, sub_n, taus = seq(0.1, 0.9, by=0.1),
cert_val = ".8"){
tmp = clean_dat %>% filter(sub == sub_n & cert == cert_val)
out = do.call(rbind, lapply(taus,
function(x) coef(rq(rt ~ reward_type, tau=x,
data=tmp))))
out <- as_tibble(out)
names(out) <- c("int", "htgtldst", "ltgtldst", "ltgthdst")
out$sub = sub_n
out$q = taus
out
}
both_subs_coefs <- do.call(rbind, lapply(both_subs, get_qq_coefs, data=clean_dat))
both_subs_coefs <- both_subs_coefs %>% pivot_longer(cols=c(htgtldst, ltgtldst, ltgthdst),
names_to="reward_cond",
values_to ="beta")
both_subs_coefs$new_ref <- NA
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "ltgtldst"] = 1
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "htgtldst"] = 2
both_subs_coefs$new_ref[both_subs_coefs$reward_cond == "ltgthdst"] = 3
both_subs_coefs$new_ref <- as.factor(both_subs_coefs$new_ref)
levels(both_subs_coefs$new_ref) <- c("ltgtldst", "htgtldst", "ltgthdst")
res = summary(lm(beta ~ q*new_ref, data=both_subs_coefs))
res
both_subs_coefs %>% ggplot(aes(x=q, y=beta, group_by=as.factor(sub),
col=new_ref)) +
geom_line() + facet_wrap(~new_ref)
ggsave("../images/qreg/betas_by_q_inds.pdf", units = "cm", width = 16, height = 16)
# replot as a grouped boxplot
both_subs_coefs %>% ggplot(aes(x=as.factor(q), y=beta, colour=new_ref,
group_by=reward_cond)) +
geom_boxplot(notch=TRUE)
ggsave("../images/qreg/betas_by_bp.pdf", units = "cm", width = 16, height = 16)
both_subs_coefs %>% ggplot(aes(x=beta, group_by=new_ref, colour=new_ref, fill=new_ref)) +
geom_histogram(alpha=0.5) + facet_wrap(~as.factor(q))
ggsave("../images/qreg/betas_hists.pdf", units = "cm", width = 16, height = 16)
